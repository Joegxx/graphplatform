#==========================================
# tomcat
#==========================================
server.port=10013
server.context-path=/dc/es

#==========================================
# kafka
#==========================================
spring.kafka.bootstrap-servers=192.168.1.161:6667,192.168.1.162:6667,192.168.1.163:6667
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.retries=3
spring.kafka.producer.acks=all
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=false
spring.kafka.consumer.max-poll-records=10
spring.kafka.consumer.group-id=dc_es
spring.kafka.listener.ack-mode=manual
# extensions
spring.kafka.consumer.batch.listener=true

#==========================================
# hadoop security
#==========================================
graph.hadoop.security.enabled=@graph.hadoop.security.enabled@
graph.hadoop.security.user-principal=dmp

#==========================================
# mysql
#==========================================
spring.datasource.url=jdbc:mysql://192.168.1.59:3306/graph_qd_dev?autoReconnection=true&useSSL=true
spring.datasource.username=crmdev
spring.datasource.password=Crm@dev_2018
spring.datasource.driverClassName=com.mysql.jdbc.Driver
spring.datasource.max-idle=10
spring.datasource.max-wait=10000
spring.datasource.min-idle=10
spring.datasource.initial-size=3

#==========================================
# elasticsearch
#==========================================
es.cluster.name=graph
es.cluster.url=192.168.1.49,192.168.1.51,192.168.1.52:9300

#logging.level.root=info